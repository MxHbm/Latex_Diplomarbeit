%############################# Anhang #################################
\appendix
%\chapter{Mathematischer Anhang}
%\chapter{Programmcodes}
\chapter{Appendix}

Write here small introduction to appendix! %TODO
\clearpage
\section{Complete Feature List}
\begin{table}[ht]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{@{}cccc@{}}
        NoCustomers            & width-height-min   & width-W-min   & volume-WLH-min   \\
        NoItems                & width-height-max   & width-W-max   & volume-WLH-max   \\
        Rel Volume             & width-height-mean  & width-W-mean  & volume-WLH-mean  \\
        Rel Weight             & width-height-std   & width-W-std   & volume-WLH-std   \\
        Rel Total Length Items & length-height-min  & length-L-min  & height-area-min  \\
        Rel Total Width Items  & length-height-max  & length-L-max  & height-area-max  \\
        Rel Total Height Items & length-height-mean & length-L-mean & height-area-mean \\
        Fragile Ratio          & length-height-std  & length-L-std  & height-area-std  \\
        Fragile Sequence       & width-length-min   & height-H-min  & area-AREA-min    \\
        Volume Balance         & width-length-max   & height-H-max  & area-AREA-max    \\
        Volume Distribution    & width-length-mean  & height-H-mean & area-AREA-mean   \\
        Weight Distribution    & width-length-std   & height-H-std  & area-AREA-std    \\
    \end{tabular}
    \caption{Complete feature list.}
    \label{tab:complete_features_list}
\end{table}

\clearpage
\section{Random Route Generation}
\label{chap:appendix:RRG}
\input{algorithms/RRG.tex}

\clearpage
\section{Feature Filter Selection}
\label{app:feature_selection}

For the feature selection the presented Algorihm~\ref{alg:filter_algorithm} was used for several levels of the minimum importance threshold
$\epsilon$ excluding low important features and for two different barriers. The aggregated results are shown in the following Figure~\ref{fig:feature_filter_parameters}.
The stacked barplots represent the dictionary count, displaying in green colors the \gls{F-Score} and in blue colors the \gls{MI} score method.
For each stacked feature bar above one of the barriers, the feature is respected in the feature sets, shown in the following Table~\ref{tab:feature_dropsets}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth,height=0.75\textheight,keepaspectratio]{pictures/feature_filter_facePlot.png}
    \caption{Aggregated results from filter algorithm resulting in different drop sets.}
    \label{fig:feature_filter_parameters}
\end{figure}

\begin{table}[ht]
    \centering
    %\renewcommand{\arraystretch}{1.2}
    \rotatebox{90}{
        \footnotesize
        \begin{tabular}{@{}P{0.04\paperheight}P{0.04\paperheight}P{0.07\paperheight}P{0.05\paperheight}P{0.46\paperheight}@{}}
            \toprule
            Name         & Barrier $B$ & Importance Threshold $\epsilon$ & Number Features & Features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \\
            \midrule
            DropSet-50-2 & 0.50        & 0.2                             & 10              & NoCustomers, NoItems, Rel Total Height Items, Rel Total Length Items, Rel Total Width Items, Volume Balance, Volume Distribution, height-area-std, volume-WLH-std, width-length-std                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \\
            \midrule
            DropSet-50-3 & 0.50        & 0.3                             & 18              & NoCustomers, NoItems, Rel Total Height Items, Rel Total Length Items, Rel Total Width Items, Volume Balance, Volume Distribution, area-AREA-std, height-area-mean, height-area-std, length-height-mean, length-height-std, volume-WLH-mean, volume-WLH-std, width-height-mean, width-height-std, width-length-mean, width-length-std                                                                                                                                                                                                                                                                                                                          \\
            \midrule
            DropSet-50-4 & 0.50        & 0.4                             & 38              & Fragile Ratio, NoCustomers, NoItems, Rel Total Height Items, Rel Total Length Items, Rel Total Width Items, Rel Weight, Volume Balance, Volume Distribution, area-AREA-min, area-AREA-std, height-H-max, height-H-mean, height-H-min, height-area-max, height-area-mean, height-area-std, length-L-max, length-L-mean, length-L-min, length-height-max, length-height-mean, length-height-min, length-height-std, volume-WLH-max, volume-WLH-mean, volume-WLH-min, volume-WLH-std, width-W-max, width-W-min, width-height-max, width-height-mean, width-height-min, width-height-std, width-length-max, width-length-mean, width-length-min, width-length-std \\
            \midrule
            DropSet-75-2 & 0.50        & 0.2                             & 7               & NoCustomers, NoItems, Rel Total Height Items, Rel Total Length Items, Rel Total Width Items, Volume Balance, Volume Distribution                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \\
            \midrule
            DropSet-75-3 & 0.50        & 0.3                             & 18              & NoCustomers, NoItems, Rel Total Height Items, Rel Total Length Items, Rel Total Width Items, Volume Balance, Volume Distribution, area-AREA-std, height-area-mean, height-area-std, length-height-mean, length-height-std, volume-WLH-mean, volume-WLH-std, width-height-mean, width-height-std, width-length-mean, width-length-std                                                                                                                                                                                                                                                                                                                          \\
            \midrule
            DropSet-75-4 & 0.50        & 0.4                             & 32              & NoCustomers, NoItems, Rel Total Height Items, Rel Total Length Items, Rel Total Width Items, Volume Balance, Volume Distribution, area-AREA-min, area-AREA-std, height-H-max, height-H-min, height-area-max, height-area-mean, height-area-std, length-L-min, length-height-max, length-height-mean, length-height-min, length-height-std, volume-WLH-max, volume-WLH-mean, volume-WLH-min, volume-WLH-std, width-W-min, width-height-max, width-height-mean, width-height-min, width-height-std, width-length-max, width-length-mean, width-length-min, width-length-std                                                                                     \\

            \bottomrule
        \end{tabular}}
    \caption{Feature dropsets with different parameter combinations of $\epsilon$ and $B$.}
    \label{tab:feature_dropsets}
\end{table}

\begin{table}[ht]
    \centering
    \small
    \caption{Model hyperparameters for feature selection.}
    \label{tab:hyperparams_feature_selection}
    \renewcommand{\arraystretch}{1.1}
    \begin{tabular}{@{}c P{0.3\textwidth}P{0.3\textwidth}@{}}
        \toprule
        \textbf{LR}                  & \textbf{XGB}                    & \textbf{FFNN}                      \\
        \midrule
        \kv{penalty}{l2}             & \kv{objective}{binary:logistic} & \kv{hidden\_layers}{[128, 64, 32]} \\
        \kv{C}{1.0}                  & \kv{eval\_metric}{logloss}      & \kv{dropout}{0.2}                  \\
        \kv{solver}{lbfgs}           & \kv{max\_depth}{15}             & \kv{lr}{0.001}                     \\
        \kv{max\_iter}{1000}         & \kv{n\_estimators}{500}         & \kv{batch\_size}{512}              \\
        \kv{class\_weight}{balanced} & \kv{learning\_rate}{0.05}       & \kv{epochs}{50}                    \\
        \kv{random\_state}{42}       & \kv{subsample}{0.8}             & \kv{pos\_weight}{null}             \\
        \kv{n\_jobs}{23}             & \kv{colsample\_bytree}{0.8}     & \kv{weight\_decay}{0.0}            \\
                                     & \kv{reg\_alpha}{0.0}            & \kv{batch\_size}{512}              \\
                                     & \kv{reg\_lambda}{1.0}           & \kv{device}{cpu}                   \\
                                     & \kv{enable\_categorical}{false} & \kv{random\_state}{42}             \\
                                     & \kv{tree\_method}{hist}         & \kv{n\_jobs}{23}                   \\
                                     & \kv{n\_jobs}{23}                &                                    \\
                                     & \kv{random\_state}{42}          &                                    \\
        \bottomrule
    \end{tabular}
\end{table}

\clearpage
\section{Parking Lot}
\label{app:trash}
With a subset from krebs the following datasets were created!
\begin{table}[ht]
    \centering
    \begin{tabular}{c c cc c c c}
        \hline
        \makecell{Multiplier $\alpha$} & \makecell{Attempts                          \\ limit $\beta$} & \makecell{Success \\threshold $\gamma$} & Routes & Balance& \gls{MCC}-Score & F1-Score \\
        \hline
        1                              & 1                  & 1 & 7616  & 60/40 &  & \\
        1                              & 1                  & 2 & 15948 & 60/40 &  & \\
        1                              & 1                  & 3 & 24573 & 60/40 &  & \\
        1                              & 2                  & 1 & 8325  & 60/40 &  & \\
        1                              & 2                  & 2 & 17217 & 60/40 &  & \\
        1                              & 2                  & 3 & 26467 & 60/40 &  & \\
        1                              & 3                  & 1 & 8683  & 60/40 &  & \\
        1                              & 3                  & 2 & 18041 & 60/40 &  & \\
        1                              & 3                  & 3 & 27535 & 60/40 &  & \\
        \hline
    \end{tabular}
    \caption[Created instances for different parameter combinations $(\alpha, \beta, \gamma)$ for \krebsADataSetText dataset.]{Created instances for different parameter combinations $(\alpha, \beta, \gamma)$ for \krebsADataSetText dataset.
        The values in the balance column stand for the share of positive and netative labels in the sample population.}
    \label{tab:created_instances_xyz_krebs}
\end{table}



\begin{table}[ht]
    \centering
    \begin{tabular}{c c c c c c}
        \toprule
        Model                          & Name     & \gls{MCC}-Score & \gls{AUROC} & F1-Score & Accuracy \\
        \midrule
        \multirow{3}{*}{\gls{LR}}      & Complete & 0.6             & 0.9         & 0.87     & 0.95     \\
                                       & Trimmed  & 0.6             & 0.9         & 0.87     & 0.95     \\
                                       & Shrinked & 0.6             & 0.9         & 0.87     & 0.95     \\
        \midrule
        \multirow{3}{*}{Decision Tree} & Complete & 0.6             & 0.9         & 0.87     & 0.95     \\
                                       & Trimmed  & 0.6             & 0.9         & 0.87     & 0.95     \\
                                       & Shrinked & 0.6             & 0.9         & 0.87     & 0.95     \\
        \midrule
        \multirow{3}{*}{\gls{FFNN}}    & Complete & 0.6             & 0.9         & 0.87     & 0.95     \\
                                       & Trimmed  & 0.6             & 0.9         & 0.87     & 0.95     \\
                                       & Shrinked & 0.6             & 0.9         & 0.87     & 0.95     \\
        \bottomrule
    \end{tabular}
    \caption{Results}
    \label{tab:dataset_model_selection_saveStrategy}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{c c c c c c}
        \toprule
        Model                           & Name       & \gls{MCC}-Score & \gls{AUROC} & F1-Score & Accuracy \\
        \midrule
        \multirow{13}{*}{\gls{LR}}      & RD-2-20-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-2-20-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-2-30-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-2-30-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-20-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-20-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-30-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-30-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-20-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-20-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-30-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-30-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-5-40-40 & 0.6             & 0.9         & 0.87     & 0.95     \\
        \midrule
        \multirow{13}{*}{Decision Tree} & RD-2-20-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-2-20-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-2-30-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-2-30-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-20-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-20-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-30-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-30-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-20-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-20-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-30-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-30-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-5-40-40 & 0.6             & 0.9         & 0.87     & 0.95     \\
        \midrule
        \multirow{13}{*}{\gls{FFNN}}    & RD-2-20-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-2-20-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-2-30-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-2-30-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-20-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-20-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-30-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-3-30-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-20-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-20-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-30-20 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-4-30-30 & 0.6             & 0.9         & 0.87     & 0.95     \\
                                        & RD-5-40-40 & 0.6             & 0.9         & 0.87     & 0.95     \\
        \bottomrule
    \end{tabular}
    \caption{Results}
    \label{tab:dataset_model_selection_randomStrategy}
\end{table}

\clearpage


\section{Parameterstudy}

\subsection{NoClasifier Variant}
\label{app:subsec:parameterstudy_noclassifier}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{pictures/parameter_study/LimitNoImpr_base_parameter_study.png}
    \caption{Parameterstudy of LimitNoImpr divided in two groups based on the average iterations.}
    \label{fig:parameterstudy_NoClassifier_limitNoImpr}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{pictures/parameter_study/RandomMoves_base_parameter_study.png}
    \caption{Parameterstudy of RandomMoves divided in two groups based on the average iterations.}
    \label{fig:parameterstudy_NoClassifier_RandomMoves}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{pictures/parameter_study/LocalSearchTypes_base_parameter_study.png}
    \caption{Parameterstudy of the order of local search neighborhoods divided in two groups based on the average iterations.}
    \label{fig:parameterstudy_NoClassifier_localSearch}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{pictures/parameter_study/PerturbationTypes_base_parameter_study.png}
    \caption{Parameterstudy of the set and order of perturbation neighborhoods divided in two groups based on the average iterations.}
    \label{fig:parameterstudy_NoClassifier_perturbation}
\end{figure}

\subsection{SpeedUp Variant}
\label{app:subsec:parameterstudy_SpeedUp}

\clearpage
\section{Branch-and-Cut Results}

The following two tables summarize the results of the branch-and-cut algorithm used for the the retrieval of train datasets
from save strategy. The following table explains each column header:

\begin{table}[ht]
    \centering
    \begin{tabular}{cc}
        \toprule
        Column Header & Description                                       \\
        \midrule
        $C^*$         & Best objective (Costs)                            \\
        Gap           & Gap to \gls{LB} in B\&C procedure                 \\
        $K^*$         & Final number of routes                            \\
        $N$           & Number of explored branch-and-bound nodes         \\
        $t$           & Runtime of algorithm; TL = Timelimit (28880 sec)  \\
        $C_0$         & Objective of start solution                       \\
        $K_0$         & Number of routes start solution                   \\
        $\Delta BKS$  & Percentage wise difference to best known solution \\
        \bottomrule
    \end{tabular}
    \caption{Column header description for B\&C results.}
    \label{tab:column_header_description_bc}
\end{table}

The results for \gendreauDataSetText are shown in Table~\ref{tab:bc_results_gendreau} and for \krebsADataSetText in Table~\ref{tab:bc_results_krebs}.
The solutions for \krebsADataSetText are categorized in three groups A, B and C classifying the solution process. Each label is shown
with the instance name. The labels have the following meaning:
\begin{itemize}
    \item A : The solution process ran without complications.
    \item B : The final solution could not be created, concrete number of vehicles $K^*$ is unknown, but Gap and $C^*$ could be retrieved from Gurobi logging file.
    \item C : Only the start solution was created, leading to missing values for the main branch-and-cut algorithm. No concrete runtime $t$ could be determined.
\end{itemize}

Applying the exact algorithm from \cite{tamke_branch-and-cut_2024} to the \krebsADataSetText is the first time for this dataset and the
average gap for this subset of instances is 3.14\%, leading to a many found optimal solutions.\footcite[cf.]{tamke_branch-and-cut_2024} Furthermore the solutions are on average
21.57\% percent better than the initally published solutions from \cite{krebs_advanced_2021}.The solutions from set P1 "Basic" were
conidered, tackling the same loading constraint set as \cite{gendreau_tabu_2006} ($\mathcal{G}$). However, the \gls{3L-CVRP} was solved and not
the \gls{3L-VRPTW} as in the forementioned paper. \footcite[cf.][pp. 858-864]{krebs_advanced_2021}

\begin{table}
    \centering
    \begin{tabular}{lrrrrl}
        \toprule
        Instance & $C^*$   & Gap  & $K^*$ & $N$     & $t$   \\
        \midrule
        E016-03m & 301.66  & 0.00 & 4     & 4290    & 21    \\
        E016-05m & 334.96  & 0.00 & 5     & 53      & 1     \\
        E021-04m & 385.53  & 0.00 & 4     & 84225   & 532   \\
        E021-06m & 430.88  & 0.00 & 6     & 98      & 5     \\
        E022-04g & 427.56  & 0.00 & 5     & 138703  & 1024  \\
        E022-06m & 498.16  & 0.00 & 6     & 726     & 11    \\
        E023-03g & 757.88  & 0.00 & 5     & 1434923 & 4226  \\
        E023-05s & 798.65  & 0.01 & 6     & 2614340 & TL    \\
        E026-08m & 630.13  & 0.00 & 8     & 4604    & 61    \\
        E030-03g & 783.79  & 0.17 & 6     & 1153008 & TL    \\
        E030-04s & 728.32  & 0.16 & 7     & 1176116 & TL    \\
        E031-09h & 610.23  & 0.00 & 9     & 394216  & 10598 \\
        E033-03n & 2649.00 & 0.14 & 6     & 564692  & TL    \\
        E033-04g & 1337.17 & 0.25 & 7     & 432649  & TL    \\
        E033-05s & 1327.09 & 0.25 & 7     & 298863  & TL    \\
        E036-11h & 698.61  & 0.00 & 11    & 20025   & 325   \\
        E041-14h & 871.63  & 0.03 & 14    & 420758  & TL    \\
        E045-04f & 1204.07 & 0.18 & 10    & 306014  & TL    \\
        E051-05e & 726.20  & 0.19 & 10    & 305879  & TL    \\
        E072-04f & 567.64  & 0.24 & 15    & 162320  & TL    \\
        E076-07s & 1040.77 & 0.25 & 15    & 197632  & TL    \\
        E076-08s & 1134.70 & 0.26 & 16    & 222779  & TL    \\
        E076-10e & 1170.51 & 0.31 & 17    & 199955  & TL    \\
        E076-14s & 1121.85 & 0.13 & 16    & 168907  & TL    \\
        E101-08e & 1375.07 & 0.29 & 20    & 162886  & TL    \\
        E101-10c & 1544.02 & 0.28 & 22    & 229882  & TL    \\
        E101-14s & 1576.76 & 0.33 & 23    & 135945  & TL    \\
        \bottomrule
    \end{tabular}
    \caption{B\&C Results for obtaining save strategy dataset from \gendreauDataSet.}
    \label{tab:bc_results_gendreau}
\end{table}

\begin{table}
    \small
    \centering
    \begin{tabular}{lrrrrlrrr}
        \toprule
        Instance Name                  & $C^*$   & Gap  & $K^*$ & $N$    & $t$   & $C_0$   & $K_0$ & $\Delta BKS$ \\
        \midrule
        $\text{012-n020-m200-bt100}^A$ & 311.78  & 0.00 & 2     & 1      & 10753 & 467.39  & 5     & -0.21        \\
        $\text{038-n020-m200-bt10}^A$  & 347.45  & 0.00 & 2     & 1      & 8019  & 543.34  & 6     & -0.13        \\
        $\text{039-n020-m200-bt10}^A$  & 337.87  & 0.00 & 2     & 1      & 11757 & 488.54  & 5     & -0.09        \\
        $\text{052-n020-m200-bt10}^A$  & 289.63  & 0.00 & 2     & 1      & 14972 & 502.17  & 6     & -0.15        \\
        $\text{054-n020-m200-bt10}^A$  & 324.87  & 0.00 & 2     & 1      & 7881  & 551.42  & 5     & 0.00         \\
        $\text{059-n020-m200-bt100}^A$ & 335.94  & 0.00 & 2     & 1      & 7884  & 514.88  & 6     & -0.10        \\
        $\text{069-n060-m200-bt10}^B$  & 1152.87 & 0.22 & 15    & 84340  & TL    & 1169.69 & 15    & -0.04        \\
        $\text{076-n060-m200-bt3}^C$   & NaN     & NaN  & NaN   & NaN    & -1    & 682.00  & 5     & -0.12        \\
        $\text{081-n060-m200-bt10}^A$  & 565.54  & 0.00 & 3     & 3114   & 10180 & 666.61  & 4     & -0.49        \\
        $\text{086-n060-m200-bt100}^A$ & 578.71  & 0.00 & 4     & 537    & 8518  & 651.16  & 5     & -0.39        \\
        $\text{116-n060-m200-bt100}^A$ & 568.14  & 0.00 & 4     & 14     & 11053 & 630.05  & 5     & -0.26        \\
        $\text{117-n060-m200-bt100}^A$ & 623.74  & 0.00 & 4     & 17208  & 26618 & 656.68  & 5     & -0.40        \\
        $\text{126-n060-m200-bt10}^A$  & 1226.45 & 0.23 & 15    & 213408 & TL    & 1241.24 & 15    & -0.05        \\
        $\text{137-n060-m200-bt3}^A$   & 538.62  & 0.00 & 3     & 6      & 11338 & 635.56  & 4     & -0.11        \\
        $\text{141-n060-m200-bt10}^A$  & 619.35  & 0.00 & 4     & 4926   & 13948 & 693.73  & 5     & -0.25        \\
        $\text{149-n060-m200-bt100}^B$ & 521.33  & 0.00 & NaN   & 321    & 22028 & 611.68  & 4     & -0.06        \\
        $\text{156-n060-m200-bt10}^B$  & 1097.58 & 0.25 & 14    & 67164  & TL    & 1070.95 & 14    & -0.08        \\
        $\text{161-n060-m200-bt100}^B$ & 1106.37 & 0.21 & 14    & 125245 & TL    & 1082.66 & 13    & -0.13        \\
        $\text{172-n060-m200-bt10}^B$  & 563.26  & 0.00 & NaN   & 8661   & 22715 & 608.35  & 5     & -0.05        \\
        $\text{204-n100-m200-bt10}^A$  & 733.05  & 0.00 & 4     & 25340  & 24701 & 787.06  & 5     & -0.49        \\
        $\text{215-n100-m200-bt3}^B$   & 1238.86 & 0.10 & 14    & 87846  & TL    & 1287.75 & 13    & -0.10        \\
        $\text{227-n100-m200-bt3}^A$   & 689.90  & 0.00 & 4     & 3079   & 2591  & 730.08  & 4     & -0.34        \\
        $\text{228-n100-m200-bt3}^A$   & 704.05  & 0.00 & 5     & 24075  & 10046 & 750.65  & 5     & -0.32        \\
        $\text{245-n100-m200-bt3}^B$   & 937.28  & 0.03 & NaN   & 83475  & TL    & 963.05  & 9     & -0.15        \\
        $\text{272-n100-m200-bt3}^B$   & 959.23  & 0.05 & NaN   & 8420   & TL    & 1106.01 & 11    & -0.23        \\
        $\text{276-n100-m200-bt10}^A$  & 1230.19 & 0.14 & 15    & 126965 & TL    & 1231.91 & 15    & -0.14        \\
        $\text{294-n100-m200-bt10}^A$  & 678.06  & 0.00 & 3     & 15     & 22781 & 769.09  & 5     & -0.21        \\
        $\text{297-n100-m200-bt100}^A$ & 746.40  & 0.00 & 4     & 22161  & 28286 & 783.66  & 5     & -0.12        \\
        $\text{299-n100-m200-bt100}^B$ & 784.50  & 0.00 & NaN   & 31547  & 20498 & 831.21  & 5     & -0.01        \\
        $\text{386-n060-m400-bt100}^A$ & 540.28  & 0.00 & 3     & 140    & 19854 & 936.23  & 10    & -0.29        \\
        $\text{390-n060-m400-bt100}^B$ & 607.91  & 0.00 & NaN   & 1      & 12800 & 967.73  & 10    & -0.27        \\
        $\text{415-n060-m400-bt10}^B$  & 577.24  & 0.00 & NaN   & 657    & 16734 & 873.01  & 9     & -0.33        \\
        $\text{423-n060-m400-bt3}^B$   & 1014.38 & 0.00 & NaN   & 1      & 10191 & 1534.87 & 23    & -0.34        \\
        $\text{438-n060-m400-bt3}^B$   & 639.95  & 0.00 & 5     & 5575   & 16971 & 809.97  & 7     & -0.06        \\
        $\text{499-n100-m400-bt3}^B$   & 767.32  & 0.00 & 4     & 17961  & TL    & 945.93  & 7     & -0.51        \\
        $\text{527-n100-m400-bt3}^A$   & 737.34  & 0.00 & 5     & 51     & 13601 & 982.10  & 8     & -0.52        \\
        $\text{529-n100-m400-bt3}^C$   & NaN     & NaN  & NaN   & NaN    & -1    & 968.32  & 8     & -0.29        \\
        $\text{542-n100-m400-bt3}^B$   & 1458.91 & 0.00 & NaN   & 13706  & 19764 & 1730.54 & 22    & -0.25        \\
        $\text{568-n100-m400-bt100}^B$ & 811.87  & 0.00 & 7     & 396    & TL    & 1020.21 & 9     & -0.29        \\
        $\text{578-n100-m400-bt10}^C$  & NaN     & NaN  & NaN   & NaN    & -1    & 1637.59 & 25    & -0.20        \\
        $\text{595-n100-m400-bt10}^B$  & 789.97  & 0.00 & NaN   & 4954   & 27730 & 1030.88 & 10    & -0.29        \\
        $\text{600-n100-m400-bt100}^B$ & 680.66  & 0.00 & NaN   & 1      & 27553 & 1027.87 & 9     & -0.21        \\
        \bottomrule
    \end{tabular}

    \caption{B\&C Results for obtaining save strategy dataset from \krebsADataSet.}
    \label{tab:bc_results_krebs}
\end{table}

\clearpage
\section{\krebsADataSetText computational challenges}
\label{app:sec:krebs_computationally_challenges}

As shown in Table~\ref{tab:dataset_comparison}, an average route of \krebsADataSetText cotains four times more items than
in the \gendreauDataSet. This makes it much more computationally challenging to create a labeled train dataset with either
the \gls{CP} solver (random strategy) or by applying the B\&C algorithm (save strategy). When the two random datasets, RD-1-1-1-10
and RD-2-30-20-10, are compared. The difference bewteen the computation time for the \gls{CP} solver is huge. The average
\gls{CP} time for the dataset constructed from \krebsADataSetText is 247 seconds, but for \gendreauDataSetText only 0.244 seconds,
which is a factor of 1000. The following boxplot shows this dispersion of \gls{CP} times for each \gls{LST}.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{pictures/comparison_krebs_gendreau/boxplot_cp_time.png}
    \caption{Boxplot showing the different computation times for \krebsADataSetText and \gendreauDataSet.}
    \label{fig:comparison_krebs_gendreau_boxplot}
\end{figure}

The time average difference is due to the group of routes labeled with \textit{Unknown} \gls{CP} status, which occurs, when
feasibility or infeasibility could not be proven in the maximum runtime of 600 seconds. From all routes from RD-1-1-1-10
33.6\% are classified as \textit{Unknown}. The distribution of \gls{LST} is shown in the following Figure~\ref{fig:comparison_krebs_gendreau_piechart}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{pictures/comparison_krebs_gendreau/pie_chart_share_cp_status.png}
    \caption{Big share of unknown labeled tours for the \krebsADataSet.}
    \label{fig:comparison_krebs_gendreau_piechart}
\end{figure}
All routes classified as \textit{Unknown} will be consideres as \textit{Infeasible}, as outlined in Section~\ref{sec:DataRetrieval}. But
as the true label is not used, the model performance is weakened as possibly feasible routes will be labeled as infeasible. The
next Figure~\ref{fig:comparison_krebs_gendreau_numberItems} shows the effect of the number of items to the \gls{CP} time and the status.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{pictures/comparison_krebs_gendreau/number_items_cp_status.png}
    \caption{Influence of number of items on the computational time.}
    \label{fig:comparison_krebs_gendreau_numberItems}
\end{figure}

The computation time literally explodes when more than 50 items are considered in a route, leading to an undefined \gls{CP} status, and
infeasible labels in the train dataset. So in the end, new long routes which improve the solution quality will always be classified as infeasible
or the exact computation time with the \gls{CP} solver takes too long to be used in a heuristic.
