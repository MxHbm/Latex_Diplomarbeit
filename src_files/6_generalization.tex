
\chapter{Generalization of Algorithm}
\label{chap:application_krebs}

\section{Dataset Retrieval}
\label{sec:krebs_data_retrieval}

In this chapter, the insights obtained from the \gls{ILS} algorithm and its classifier-based variants are extended by
applying them to instances from the \krebsADataSetText dataset. Building on
the previous findings, two complementary approaches are investigated. The first approach generates training datasets
directly from the \krebsADataSetText instances, whereas the second employs pretrained classifiers derived from the
\gendreauDataSetText dataset. 48 of 600 instances were randomly selected for evaluation.
The comparative results are presented in Section~\ref{sec:results_krebs}.
This section presents the training data retrieved with the save and random-strategy (see Section~\ref{sec:DataRetrieval}). Furthermore,
the training datasets are analyzed and compared to the training datasets of \gendreauDataSet. Subsequently, one dataset is selected by
comparing the cross performance metrics of all datasets, similar to the procedure presented in Section~\ref{sec:dataset_selection}, but no
validation dataset is constructed.

\subsubsection{Random Retrieval Strategy}
The feasibility check is more challenging, because the number of items and customers per average route is higher than in the
\gendreauDataSetText dataset (see Section~\ref{fig:dataset_comparison}). Therefore, the following random datasets include fewer
routes and are shown in Table~\ref{tab:random_instances_krebs}.
\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{l c c c c c }
        \toprule
        Name        & Routes & Routes Len = 2 & Balance   & Rel. Vol & Rel. Mass \\
        \midrule
        RD-1-1-1-6  & 4836   & 92             & 75.3/24.7 & 0.30     & 0.52      \\
        RD-1-1-1-8  & 6099   & 94             & 69.7/30.3 & 0.33     & 0.57      \\
        RD-1-1-1-10 & 6707   & 80             & 64.9/35.1 & 0.37     & 0.63      \\

        \bottomrule
    \end{tabular}
    \caption{Random-strategy train datsets of \krebsADataSet instances.}
    \label{tab:random_instances_krebs}
\end{table}

Further insights into the computational challenges of the classification of the random dataset  are presented in Section~\ref{sec:challenges_krebs_random}.
In general, the balance between
feasible and infeasible instances is reversed, while the relative tour volume is significantly smaller, compared to the random datasets listed in Table~\ref{tab:created_instances_xyz_gendreau}.
This effect can be attributed to the small parameter values of the \gls{RRG}
algorithm ($\alpha$, $\beta$, $\gamma$), which cause an earlier termination. However, the average number of customers per route
is approximately twice as high (see Figure~\ref{fig:route_cust_no_krebs_new}).

\subsubsection{Save Retrieval Strategy}

Constructing the different save-strategy datasets was more complex due to the longer runtime of the \gls{CP} solver and the undefined
handling of \textit{Invalid} and \textit{Unknown} loading statuses. Section~\ref{sec:challenges_krebs_save} examines these
challenges in more detail. The branch-and-cut results are shown in Table~\ref{tab:bc_results_krebs}, while
Table~\ref{tab:saved_instances_krebs} presents the generated save-strategy datasets.

\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{l c c c c c c }
        \toprule
        Name           & Sets                 & Routes & Routes Len = 2 & Balance   & Rel. Vol & Rel. Mass \\
        \midrule
        KS-Complete-WS & \multirow{3}{*}{Yes} & 261989 & 220860         & 92.4/7.6  & 0.18     & 0.20      \\
        KS-Trimmed-WS  &                      & 41337  & 208            & 52.1/47.9 & 0.58     & 0.63      \\
        KS-Shrunken-WS &                      & 56962  & 15833          & 65.3/34.7 & 0.43     & 0.48      \\        \midrule
        KS-Complete    & \multirow{3}{*}{No}  & 256786 & 220860         & 94.3/5.7  & 0.16     & 0.19      \\
        KS-Trimmed     &                      & 36134  & 208            & 59.6/40.4 & 0.54     & 0.61      \\
        KS-Shrunken    &                      & 51759  & 15833          & 71.8/28.2 & 0.39     & 0.46      \\

        \bottomrule
    \end{tabular}
    \caption{Save-strategy train datsets from \krebsADataSet.}
    \label{tab:saved_instances_krebs}
\end{table}

The Complete datasets are dominated by routes with two customers, resulting in strongly imbalanced datasets. Consequently,
only the modified datasets, either shrunken or trimmed, are used for model training. However, the trimmed dataset is excluded
from further analysis, as it cannot predict feasible routes with two customers, given that only infeasible tours of this route
length are contained within it causing model performance issues descibed in Section~\ref{sec:dataset_selection}.

\subsubsection{Dataset Selection}

To identify the best dataset for the classifier, cross-performance metrics between all datasets are compared. However,
the cross-performance between save-strategy datasets is excluded.\footnote{As KS-Shrunken contains the subset of routes from KS-Shrunken-WS.} For all datasets,
the filter performance results from Section~\ref{sec:feature_filter_results} are adopted and drop set DS-50-4 is chosen,
as model performance was generally worse due to the high variability (noise) among datasets. The mean performance metrics
across all model types are shown in the next Table~\ref{tab:featurePerformance_krebs}.

\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{lrrrr}
        \toprule
        Base Dataset   & MCC            & F1-Score       & Accuracy       & AUROC          \\
        \midrule
        KS-Shrunken    & 0.724          & 0.887          & 0.859          & 0.970          \\
        KS-Shrunken-WS & 0.738          & 0.893          & 0.866          & \textbf{0.972} \\
        RD-1-1-1-6     & 0.796          & 0.936          & 0.912          & 0.968          \\
        RD-1-1-1-8     & \textbf{0.799} & 0.939          & 0.915          & 0.969          \\
        RD-1-1-1-10    & 0.798          & \textbf{0.940} & \textbf{0.916} & 0.969          \\
        \bottomrule
    \end{tabular}
    \caption{Average performance metrics across \krebsADataSetText datasets.}
    \label{tab:featurePerformance_krebs}
\end{table}

Overall, the considerably smaller random datasets outperform the others across all metrics except for the \gls{AUROC} value. Section~\ref{sec:krebs_model_results}
present detailed performance results by model type and confirm the superior performance of the random-strategy datasets.
As discussed in Section~\ref{sec:modelselection}, the \gls{XGB} model performs particularly well on smaller datasets and is therefore selected for the subsequent analysis.
Table~\ref{tab:mdoe_performance_krebs_model_type} indicates that RD-1-1-1-6 achieves the best performance on the \gls{XGB} dataset. However, this choice remains somewhat arbitrary,
as the differences among the top-performing random datasets are marginal.



\section{Generalize \gendreauDataSetText models}
\label{sec:krebs_data_pretrained_models}

Two alternatives emerge for this variant. On the one hand, the best model type and corresponding dataset can be selected
from the computational study of the \gendreauDataSet dataset (see Section~\ref{sec:comparison_ils_variants}). On the other hand, the
best model type and dataset can be determined by comparing the performance across all five \krebsADataSetText retrieved datasets introduced in the previous section.
As the second alternative combines the strategies of using the same model configuration and adapting it to new datasets, it is
only examined if the best variant–model–dataset combinations identified in Section~\ref{sec:comparison_ils_variants} yield good
results for other \gls{3L-CVRP} datasets. To reduce the computational runtime, only the two best performing variants, NoClassifier
and SpeedUp, are selected (see Table~\ref{tab:final_best_results_gendreau}). The following configurations are chosen based
on the results of all classifier variants compared in Section~\ref{sec_final_comparison_results}.

\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{l c c  }
        \toprule
        Variant      & Model Type & Dataset        \\
        \midrule
        SpeedUp      & XGB        & GD-Shrunken-WS \\
        NoClassifier & -          & -              \\
        \bottomrule
    \end{tabular}
    \caption{Variant configuration for generalization of \gendreauDataSetText results.}
    \label{tab:model_configuration_krebs}
\end{table}

The \gls{XGB} model type was chosen, as it achieved slightly better results
regarding rejection rate and number of iterations, and to increase overall comparability.
The dataset GD-Shrunken-WS minimizes the rejection rate and maximizes the number of iterations for the SpeedUp variant.

\section{Results}
\label{sec:results_krebs}
As shown in Chapter~\ref{app:sec:krebs_computationally_challenges}, the computation of \krebsADataSetText instances comprises
challenges. Therefore, the algorithmic design is changed. As the computation of the start solution takes averagely \textcolor{red}{1000000000000 seconds}
during the B\&C algorithm (20 seconds for the \gendreauDataSet), much longer running times are needed for the \gls{ILS} algorithm.
Every instance is run only once. Furthermore, the time limit for one instance
is dependent, if the startsolution is given or will be computed during the algorithm. The start solutions are taken from the branch-and-cut
results (see Section~\ref{tab:bc_results_krebs}). Furthermore, the effect of the parameter \texttt{UseFilterStartSolution} is re-evaluated to determine whether
it provides a positive impact for instances requiring substantially longer constructive computation times. For the \gendreauDataSetText dataset,
enabling this parameter reduced the constructive time by approximately 50\%, indicating a clear efficiency gain (see Table~\ref{tab:numerical_results_paramStudy_classifiers}). However,
the overall \gls{RPD} slightly worsened due to losses in solution quality, as false predicted routes from the Filter strategy were not verified.
Consequently, an even stronger leverage effect is expected for the more complex Krebs dataset, where computation time is more critical
and any feasible start solution is essential to initialize the main \gls{ILS} algorithm. The configurations shown in Table~\ref{tab:condigurations_krebs_results} are selected for the
Specialization and generalization approach. To distinguish between the variants, the SpeedUp with \texttt{UseFilterStartSolution} is
called FilterSpeedUP in the following.

\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{l c c c c }
        \toprule
        Approach                        & $T$                  & Startsolution                    & Variant               & UseFilter \\
        \midrule
        \multirow{3}{*}{Specialization} & 1 h                  & Given                            & SpeedUp/ NoClassifier & False     \\\cmidrule(lr){2-5}
                                        & \multirow{2}{*}{2 h} & \multirow{2}{*}{ModifiedSavings} & SpeedUp/ NoClassifier & False     \\
                                        &                      &                                  & SpeedUp               & True      \\ \midrule
        \multirow{3}{*}{Generalization} & 1 h                  & Given                            & SpeedUp               & False     \\\cmidrule(lr){2-5}
                                        & \multirow{2}{*}{2 h} & \multirow{2}{*}{ModifiedSavings} & SpeedUp/ NoClassifier & False     \\
                                        &                      &                                  & SpeedUp               & True      \\
        \bottomrule
    \end{tabular}
    \caption[Computation configurations for the \krebsADataSetText dataset.]{Computation configurations for the \krebsADataSetText dataset. $T$ stands for the time limit of the ILS algorithm
        and UseFilter defines the usage of filter feasibility check in constructive heuristic.}
    \label{tab:condigurations_krebs_results}
\end{table}
