\chapter{Algorithm}
\label{chap:algorithm}
The focus of the algorithm is not on implementing the most advanced metaheuristic for routing and loading,
but rather on using a simple and adaptable algorithm to explore how a trained classifier can be integrated and what
impacts this integration has on the algorithmâ€™s performance. Therefore, the \gls{ILS}
algorithm was chosen, a moderate and simple algorithm used regularly for the \gls{VRP}. First, the principal
algorithm and the neighborhoods will be explained. Second, the emphasis is set on the feasibility check for the loading,
both which options are present and where to include it. Third, different strategies for the usage of the
classifier are presented.

\section{Principal Algorithm}
\label{sec:algorithm}
The \gls{ILS} algorithm was proposed by \cite{lourenco_iterated_2003} and has the goal to incorporate simplicity and generality.
As the authors say, metaheuristics became recently too sophisticated and problem specific and lack the purpose of
being applied to different use cases. The main concept of the metaheuristic is based on iterations, in which the current
solution is first perturbed (diversification) and afterwards improved by different sequential \gls{LS} neighborhoods
(intensification). The solution process restarts with the best solution after a number of iterations without improvement
or continues with the current solution to explore new areas of the solution space.
The proposed general algorithm is depicted in Algorithm~\ref{alg:base_ILS}. Here, $s^*$ stands for the best solution,
$s\sp{c}$ for the current solution and $s\sp{\prime}$ for a perturbed neighbor of $s^c$. Note that the symbol $s^c$
is used as a placeholder, and shows the current state of the solution after each step. So, the current solution
$s^c$ before the perturbation is usually different from $s^c$ after the \gls{LS}, but, as the non-deterministic
perturbation and \gls{LS} can return to the same solution, ambiguity exists to a certain extent.
Notably, the constructive heuristic and the neighborhoods for perturbation and \gls{LS} need to be adapted to
each use case. The acceptance criterion can have several different implementations. To name a few, the algorithm could always
generate a random restart after a certain number of iterations without improvement, set back to the actual best solution
obtained or incorporating a simulated annealing component accepting also worse solutions in the beginning. The major challenge is
to find a fitting perturbation mechanism, which allows to explore new solution space areas, without falling back to previous solutions
after the \gls{LS}. Therefore it should be guaranteed, that several iterations can be used for diversification and
intensification before resetting the algorithm. History is referred in the algorithm to some knowledge base,
to save the values of previos solution to skip already reached solutions or the counter for iterations without improvement since the
last restart or solution improvement.\footcite[cf.][]{lourenco_iterated_2003}
\input{algorithms/ILS_base.tex}

The presented general \gls{ILS} is adapted to obtain good solutions for the \gls{3L-CVRP}, where for the \gls{VRP}
the overall costs need to be minimized, and every single tour needs to represent a feasible packing of the \gls{CLP}.
The Algorithm~\ref{alg:principal_ILS} is used. The perturbation applies $R$ random moves
to the current solution for each neighborhood selected. In the \gls{LS}
the selected neighborhoods are sequentially walked through updating the current solution for each feasible improvement on
the current solution. The acceptance criterion controls the solution process, updating the current solution, until a new overall
best solution was found or the limit for iterations without improvement (attempts limit $a$) is reached. Then, the current solution is resetted
to the best solution found. It needs to be investigated, if the random perturbation is able to leave local optima
when no improvements can be found or if this acceptance criterion is sufficient. But as the feasibility check of the loading
is time crucial, the routing algorithm is kept simple. The \gls{ILS} has a dual stop criterion, existing on a maximum time limit $T$ for the metaheuristic and a maximum number of
iterations since the last improvement of the best solution $A_{max}$. The second criterion is added
to avoid exponential cycling of solutions, after the best solution is found and/or only a limited amount of feasible moves is available.\footnote{Results compared with
    minimal costs due to \cite{tamke_branch-and-cut_2024}}

\input{algorithms/ILS_principal.tex}

In Section~\ref{sec:parameter_study} a parameter study is conducted to test different
levels for the attempts limit $a$, the random moves $R$ and the order of the \gls{LS} and perturbation neighborhoods.

\subsubsection{Constructive}
The initial solution is obtained by using the savings algorithm from \cite{clarke_scheduling_1964}. It is one of
most applied constructive algorithms for the \gls{VRP}, and is described by the following procedure. In the beginning
a single tour is created for every customer and the potential savings, when two customers are combined in one tour are calculated.
Afterwards the tours are merged until no negative savings are available, and the
procedure terminates with $K$ tours. \footcite[cf.][]{clarke_scheduling_1964} However, this constructive algorithm needs to be adapted
as the minimum distance solution can exceed the maximum numbers of vehicles $K_{max}$ allowed per instance.
The modified savings approach was proposed by \cite{zhang_evolutionary_2015} to generate initial feasible solutions.
The modification is based on two steps, if the number of routes of the solution is exceeding the vehicle limit. First,
the merge procedure continues until $K = K_{max}$ or no feasible merges exist. Second, a repair procedure is invoked
by removing the routes from the solution with the least volume utilization and sorting the unassigned customers by
decreasing volume demand. Afterwards, the customers are tried to be reinserted at positions with the least
cost surplus. If no position could be found, the customer is inserted in a random chosen route by removing
other customers from this route to create free capacity. The second procedure is repeated until the
number of routes is $K = K_{max}$.\footcite[cf.][p. 24]{zhang_evolutionary_2015}

\subsubsection{Neighborhoods}
\label{sec:neighborhoods}

The respected neighborhoods are divided in \textit{Intra}, changes on the customers within one tour, and \textit{Inter} neighborhoods,
changes between two tours. The following neighborhoods are implemented for each group:\footcite[cf.][p. 89f]{toth_vehicle_2014}

\begin{table}[ht]
    \centering
    \begin{tabular}{@{}P{0.3\textwidth}P{0.3\textwidth}@{}}
        \toprule
        \textbf{Intra} & \textbf{Inter} \\
        \midrule
        Swap           & Swap           \\
        Insertion      & Insertion      \\
        TwoOpt         &                \\
        \bottomrule
    \end{tabular}
\end{table}
Hereby, is a swap move defined by changing the position of two customers and insertion by removing one customer from one route
and replacing it in the same route (\textit{Intra}) or in another route (\textit{Inter}). A \textit{TwoOpt} move is characterized, when two arcs are deleted
from one route and are reinserted by swapping the indices of the arcs leading to a inversion of all customers between these two arcs.
For example, when the arcs $x_{12}$ are $x_{45}$ are selected the resulting arcs will be $x_{14}$ and $x_{25}$. To distinguish these
neighborhoods in the following section, they will be named with their respective group, e.g. \textit{InterSwap}. Additionally, a sixth
neighborhood is implemented deleting empty tours with no customers and is called \textit{DeleteEmptyRoutes}.
The neighborhoods for the perturbation are built upon the \textit{Inter} neighborhoods, and are characterized by $R$ random moves of
this respective neighborhood. They are named \textit{R-Insertions} and \textit{R-Swaps} in the
following. The perturbation consists of inter neighborhoods as the diversification of the solution is
greater as with intra random moves. Regarding to \cite{lourenco_iterated_2003}, it is important, that perturbation holds the potential
to escape local optima and lays the foundation for a succesful \gls{LS}. These two perturbation neighborhoods
can be configured in four ways in the algorithm, considering either only one or both of them. For the latter, the order becomes relevant.
Other perturbation mechanisms like \textit{FourOpt} or \textit{BlockInsertion} were not considered as the feasibility check of the loading is the limiting factor even though
the perturbation has an important impact in creating new structural solutions.\footcite[cf.][pp. 329--332]{lourenco_iterated_2003}

\section{Local Search and Perturbation}
\label{sec:LSandPerturbation}

In the \gls{LS} all selected neighborhoods are sequentially applied once. In the beginning, all moves for the respective neihghborhood,
which lower the routing cost of the current solution, are found. A move is defined by the modification of the current solution to
obtain a new solution. Note, that the loading is only respected with bound checks of the maximum volume and weight
allowed per vehicle at this step. Afterwards, all moves are sorted with decreasing cost savings and are applied to the current solution. Now, it is tested
if the new solution aligns to the three-dimensional loading constraints. This feasibility check will be discussed in
detail in the next section. If the new route is feasible, the \gls{LS} restarts for this solution, if it is infeasible
the move will be undo and the next move will be applied. If there are no moves with negative savings left to apply, the search
terminates and continues with the next neighborhood. The procedure is visualized in Figure~\ref{fig:LocalSearch} for one \gls{LS} neighborhood.
The perturbation has a similar approach. Here, in each neighborhood a certain number of random moves $R$ must be found
before the perturbation neighborhood terminates. The random move creation must not violate the maximum volume and weight limit of the vehicle.
The perturbation can be further controlled by the order and number of neighborhoods being applied, as discussed in the last section.
The procedure is visualized in the following Figure~\ref{fig:Perturbartion}.
\input{tikz/LocalSearch.tex}

\section{Loading Feasibility Check}
\label{sec:FeasibilityCheck}
So far the description of the algorithm was reduced to minimizing the costs of the \gls{VRP} masterproblem and in vague
requirements, that new solutions need to be feasible regarding the three-dimensional loading constraints.
This check is time-consuming as every item needs to be placed accordingly in the container, testing all possible combinations.
The \gls{CLP} is $NP$-hard and as shown in Section~\ref{sec:classical_solution_approaches} most approaches rely on fast, but not
optimal heuristics. The aim of the thesis is to determine, if the usage of a binary classifier can bring quality and
speed advantages in comparison to the baseline of only using the exact solver.
As this work is a potential study, the combination with an exact solver is sufficient to derive insights for other use cases
leveraging either exact \gls{3L-CVRP} algorithms or exisiting metaheuristics with a classifier.
Before explaining how both tools can be integrated in the algorithm, strengths and weaknesses of
each approach are shown in the following overview:

\begin{figure}[ht]
    \centering
    \begin{minipage}[centering]{0.45\textwidth}
        \textbf{CP Solver}
        \begin{itemize}
            \item Returns exact loading status
            \item Computational heavy
            \item No need to verify solution
        \end{itemize}
    \end{minipage}
    \begin{minipage}[centering]{0.45\textwidth}
        \textbf{Binary Classifier}
        \begin{itemize}
            \item Fast to classify route
            \item Solution needs to be verified
            \item Adaptable acceptance threshold $y$
        \end{itemize}
    \end{minipage}
\end{figure}

The classifier has the potential to speed up the \gls{3L-CVRP} solution process, but accepted solutions need to be
verified with the \gls{CP} solver in a certain pattern to avoid false positive solutions during the algorithm.
Therefore, the following four feasibility checks are introduced, which determine how the loading feasibility can be checked and are
visualized in Figure~\ref{fig:tikz_four_variants}

\input{tikz/FeasibilityChecks.tex}

The first approach is the \textit{SpeedUp} strategy, where only the classifier is used for feasibility checks during perturbation and
\gls{LS}. The parameter $\varrho$ defines the frequency of verifying the actual solution with the exact \gls{CP} solver and
the current solution is either rejected or accepted.
The amount of false positive labeled routes is crucial, as the probability to reject the solution grows likewise. It needs
to be studied, which influence the parameter $\varrho$ has, as infeasible tours can become feasible
again after several iterations without verification.
The second strategy is called \textit{Filter}, here classifier and \gls{CP} solver are called sequentially for every
feasibiliy check. The goal is to filter out infeasible routes before verifying them exactly to save time in the exact check.
All false negative labeled routes represent a potential solution quality loss, as those tours will never be considered to be accepted.
The third strategy is a hybrid form between the last two presented, where the chosen strategy, \textit{Filter} or \textit{SpeedUp},
is dependent on the neighborhood structure (Perturbation, Intra- and Interneighborhood). The last and fourth strategy, \textit{NoClassifier}, is the benchmark
for the other strategies and here the \gls{CP} solver is solely used. Each check strategy can be enhanced as variation of the \gls{ILS}
algorithm leveraging its feasibility check strategy. These variations are further explained in Figure~\ref{fig:four_variants} by highlighting, where
in the algorithm, which kind of feasibility check is applied. The $\clubsuit$ represents the usage of the \gls{CP} Solver and
$\bigstar$ the sole usage of the classifier (SpeedUp variant). The concatenation $\bigstar\clubsuit$ imply the usage of the Filter
variant and \(\clubsuit \backslash \bigstar\clubsuit\) if the \gls{CP} Solver or Filter is applied. \(\bigstar\backslash\clubsuit\)
indicates the Hybrid variant, and either the SpeedUp or the Base strategy is applied. In the initial \gls{LS} the same
feasibility check is applied as in the \gls{LS}.

\input{tikz/classifier_approaches.tex}
\FloatBarrier
During the construction, the \textit{SpeedUp} strategy can hardly be applied, which has two reasons. Firstly, this strategy relies
on rejecting feasible predicted solutions by the \gls{CP} solver and resetting the solution to previous feasible solutions.
Secondly, the procedure of the modified savings algorihm is deterministic and repetitions will lead to the same solutions. In this
case it needs to be investigated, if the \textit{Filter} strategy can speed up the solution process in the constructive without
great solution quality loss. In the next chapter a computational study will be conducted for each variant to compare them. To facilitate this approach,
a comparison of various published \gls{3L-CVRP} datasets will be conducted to compare and identify the most appropriate
dataset for training a binary feasibility classifier and the results of dataset selection and training will be presented.
